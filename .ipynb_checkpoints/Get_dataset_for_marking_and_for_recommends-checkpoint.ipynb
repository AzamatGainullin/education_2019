{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "import time\n",
    "import numpy as np\n",
    "import iexfinance\n",
    "from iexfinance.stocks import get_historical_intraday\n",
    "from collections import Counter\n",
    "import os\n",
    "import copy\n",
    "from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "traindata_standard = get_traindata_standard_with_mart_2019(traindata_standard)\n",
    "len(traindata_standard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#формирование списка sp_500\n",
    "def get_sp500(k=3):\n",
    "    \n",
    "    sp500=pd.read_excel('C:/Users/user/Documents/Модуль биржа по фракталам/sp500_symbols.xlsx')\n",
    "    sp500=list(sp500['symbol'])\n",
    "    return sp500[1:len(sp500):k]\n",
    "\n",
    "#Тренировочные данные - загрузка\n",
    "def traindata_download(k=30):\n",
    "\n",
    "    companies={}\n",
    "    path='C:/Users/user/Documents/Модуль биржа по фракталам/minute_by_andrey/'\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        files=[files[i] for i in range(len(files)) if i%k==0] #БЕРЕМ ПОКА ТОЛЬКО КАЖДЫЙ 30-ЫЙ ФАЙЛ\n",
    "        for _file in files:\n",
    "            text=str(_file)\n",
    "            splitted_text = text.split(\".\")\n",
    "            tiker=splitted_text[0]\n",
    "            if tiker in sp500:\n",
    "\n",
    "                companies[tiker]=pd.read_csv('minute_by_andrey/'+_file)\n",
    "    return companies\n",
    "\n",
    "#Тренировочные данные - приведение к нужному виду\n",
    "def traindata_making_standard(companies):\n",
    "    DF={}\n",
    "    step=0\n",
    "    for i in companies.keys():\n",
    "        try:\n",
    "\n",
    "            df=companies[i].copy(deep=True)\n",
    "\n",
    "            df.drop(['OPEN','CLOSE','VOLUME'],axis=1,inplace=True)\n",
    "\n",
    "            df.index=pd.to_datetime(df['Date'])\n",
    "            df.drop('Date',axis=1,inplace=True)\n",
    "\n",
    "            df.rename(columns={'HIGH': 'High', 'LOW': 'Low'}, inplace=True)\n",
    "            df['company']=str(i)\n",
    "            df=df[df['High'].notnull()]\n",
    "            \n",
    "            if step == 0:\n",
    "                indexes=pd.date_range(start=df.index[0], end=df.index[-1], freq='1Min')\n",
    "                dfs = pd.DataFrame(index=indexes)\n",
    "                dfs['day_number'] = dfs.index.date\n",
    "                dti=pd.date_range(start=df.index[0], end=df.index[-1], freq='B')\n",
    "                dfs_filtered=(dfs.loc[dfs['day_number'].isin(pd.DataFrame(index=dti).index.date)])\n",
    "                dfs_filtered_between_time=dfs_filtered.between_time(start_time='09:30', end_time='16:00')\n",
    "            step = step + 1\n",
    "            df_filtered = (df.index.isin(dfs_filtered_between_time.index))\n",
    "            \n",
    "            \n",
    "                \n",
    "                \n",
    "            \n",
    "            \n",
    "            DF[i]=df[df_filtered]\n",
    "\n",
    "        except:\n",
    "            pass\n",
    "    return DF\n",
    "\n",
    "#Данные: ресэмплирование на нужные минутные интервалы перед подсчетом фрактальных точек\n",
    "def resampling_standard_data(DF, minutes=5):\n",
    "    \n",
    "    resample_time=str(minutes)+str('Min')\n",
    "\n",
    "    DF_1={}\n",
    "    for i in DF.keys():\n",
    "        try:\n",
    "\n",
    "            df1=DF[i].copy(deep=True)\n",
    "            df=pd.DataFrame()\n",
    "            df['High'], df['Low']=df1['High'].resample(resample_time).max(), df1['Low'].resample(resample_time).min()\n",
    "            df['company']=str(i)\n",
    "            df=df[df['High'].notnull()]\n",
    "\n",
    "\n",
    "            DF_1[i]=df\n",
    "\n",
    "        except:\n",
    "            pass\n",
    "    return DF_1\n",
    "\n",
    "#Данные: после ресэмплирования, получение фрактальных среднесрочных точек для одной фирмы\n",
    "def get_fractal_points_for_one_df(df):\n",
    "    \n",
    "    hh=(df['High']>df['High'].shift(1))&(df['High']>df['High'].shift(-1))\n",
    "    ll=(df['Low']<df['Low'].shift(1))&(df['Low']<df['Low'].shift(-1))\n",
    "\n",
    "    df_new_hh=pd.DataFrame({'High':df[hh].High})\n",
    "    frac_hh=(df_new_hh['High']>df_new_hh['High'].shift(1))&(df_new_hh['High']>df_new_hh['High'].shift(-1))\n",
    "\n",
    "    df_new_ll=pd.DataFrame({'Low':df[ll].Low})\n",
    "    frac_ll=(df_new_ll['Low']<df_new_ll['Low'].shift(1))&(df_new_ll['Low']<df_new_ll['Low'].shift(-1))\n",
    "\n",
    "    df_newest=pd.DataFrame({'Srhigh':df_new_hh[frac_hh].High,'Srlow':df_new_ll[frac_ll].Low})\n",
    "    \n",
    "    return df_newest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ПОДСЧЕТ МОМЕНТОВ УВЕРЕННОГО РАЗВОРОТА ПО РЕСЭМПЛИРОВАННЫМ ФРАКТАЛЬНЫМ ТОЧКАМ - по одной фирме.\n",
    "# Возвращается список таймстэмпов\n",
    "def get_high_low_timestamps_for_one_df(df_newest):\n",
    "    spisok_low=[]\n",
    "    spisok_high=[]\n",
    "    for y in range(10, len(df_newest)):\n",
    "        try:\n",
    "            if df_newest['Srlow'].iat[y] >= 0:\n",
    "                y_point=y\n",
    "                y=y-1\n",
    "                while not df_newest['Srlow'].iat[y] >= 0:\n",
    "                    y=y-1\n",
    "                srlow3=y\n",
    "\n",
    "                y=y-1\n",
    "                while not df_newest['Srlow'].iat[y] >= 0:\n",
    "                    y=y-1\n",
    "                srlow2=y\n",
    "\n",
    "                y=y_point-1                     \n",
    "                while not df_newest['Srhigh'].iat[y] >= 0:\n",
    "                    y=y-1\n",
    "                srhigh=y                    \n",
    "\n",
    "                if srhigh<srlow3:\n",
    "                    if df_newest['Srlow'].iat[y_point]>df_newest['Srlow'].iat[srlow3] and df_newest['Srlow'].iat[srlow2]>df_newest['Srlow'].iat[srlow3]:\n",
    "                        moment_low=df_newest.index[srlow3]\n",
    "                        spisok_low.append(moment_low)\n",
    "        except:\n",
    "            pass\n",
    "    # а теперь по моментам хай    \n",
    "    for y in range(10, len(df_newest)):\n",
    "        try:\n",
    "            if df_newest['Srhigh'].iat[y] >= 0:\n",
    "                y_point=y\n",
    "                y=y-1\n",
    "                while not df_newest['Srhigh'].iat[y] >= 0:\n",
    "                    y=y-1\n",
    "                srhigh3=y\n",
    "\n",
    "                y=y-1\n",
    "                while not df_newest['Srhigh'].iat[y] >= 0:\n",
    "                    y=y-1\n",
    "                srhigh2=y\n",
    "\n",
    "                y=y_point-1                     \n",
    "                while not df_newest['Srlow'].iat[y] >= 0:\n",
    "                    y=y-1\n",
    "                srlow=y                    \n",
    "\n",
    "                if srlow<srhigh3:\n",
    "                    if df_newest['Srhigh'].iat[y_point]<df_newest['Srhigh'].iat[srhigh3] and df_newest['Srhigh'].iat[srhigh2]<df_newest['Srhigh'].iat[srhigh3]:\n",
    "                        moment_high=df_newest.index[srhigh3]\n",
    "                        spisok_high.append(moment_high)\n",
    "        except:\n",
    "            pass\n",
    "    return spisok_high, spisok_low"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Получение полного списка таймстэмпов по всем фирмам\n",
    "def get_timestamps_for_all(traindata_resampled):\n",
    "    companies = traindata_resampled.keys()\n",
    "    spisok_high_global = []\n",
    "    spisok_low_global = []\n",
    "    for company in companies:\n",
    "        df=traindata_resampled[company].copy(deep=True)\n",
    "        df_newest = get_fractal_points_for_one_df(df)\n",
    "        spisok_high, spisok_low = get_high_low_timestamps_for_one_df(df_newest)\n",
    "        spisok_high_global.append(spisok_high)\n",
    "        spisok_low_global.append(spisok_low)\n",
    "    spisok_high_all = []\n",
    "    spisok_low_all = []    \n",
    "    for item in spisok_high_global:\n",
    "        for i in item:\n",
    "            spisok_high_all.append(i)\n",
    "    for item in spisok_low_global:\n",
    "        for i in item:\n",
    "            spisok_low_all.append(i)            \n",
    "            \n",
    "    \n",
    "    return spisok_high_all, spisok_low_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#получение чернового датасета по минутам\n",
    "def get_unsampled_dataset(traindata_standard, times = [3,7,15]):\n",
    "    step = 0\n",
    "    for minute in times:\n",
    "        traindata_resampled = resampling_standard_data(traindata_standard, minutes=minute)\n",
    "        spisok_high_all, spisok_low_all = get_timestamps_for_all(traindata_resampled)\n",
    "        if step == 0:\n",
    "            max_time = max(max(spisok_high_all), max(spisok_low_all))\n",
    "            min_time = min(min(spisok_high_all), min(spisok_low_all))\n",
    "            indexes=pd.date_range(start=min_time, end=max_time, freq='1Min')\n",
    "            \n",
    "            \n",
    "        \n",
    "            \n",
    "            dfs = pd.DataFrame(index=indexes)\n",
    "            dfs['day_number'] = dfs.index.date\n",
    "            dti=pd.date_range(start=min_time, end=max_time, freq='B')\n",
    "            dfs_filtered=(dfs.loc[dfs['day_number'].isin(pd.DataFrame(index=dti).index.date)])\n",
    "            dfs_filtered_between_time=dfs_filtered.between_time(start_time='09:30', end_time='16:00')\n",
    "            \n",
    "            \n",
    "            unsampled_dataset = pd.DataFrame(index=dfs_filtered_between_time.index)\n",
    "        step = step + 1\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "        \n",
    "        slovar_high = Counter(spisok_high_all)\n",
    "        slovar_low = Counter(spisok_low_all)\n",
    "\n",
    "        unsampled_dataset['highes'+str(minute)] = pd.Series(data=list(slovar_high.values()), index=list(slovar_high.keys()))\n",
    "        unsampled_dataset['lowes'+str(minute)] = pd.Series(data=list(slovar_low.values()), index=list(slovar_low.keys()))\n",
    "\n",
    "    return unsampled_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Предподготовка traindata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#traindata = traindata_download(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#traindata_standard = traindata_making_standard(traindata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Предподготовка testdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Загрузка тестовых данных\n",
    "def testdata_download(start_day=datetime.datetime(2019,4,1), end_day=datetime.datetime(2019,6,18)):\n",
    "    dti=pd.date_range(start_day,end_day, freq='B')\n",
    "    companies={}\n",
    "    for i in sp500:\n",
    "\n",
    "        get=pd.DataFrame()\n",
    "        for date in dti:\n",
    "            try:\n",
    "                get_current=pd.read_excel('C:/Users/user/Documents/Модуль биржа по фракталам/iex_intraday/'+str(i)+'_'+str(date)[:-9]+'.xlsx', dtype={'date':object})\n",
    "                get=get.append(get_current)\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "        companies[i]=get\n",
    "    return companies\n",
    "\n",
    "#Тестовые данные: преобразование в формат готовности перед ресэмплированием\n",
    "def testdata_making_standard(companies):\n",
    "    traindata_standard={}\n",
    "    for company in companies.keys():\n",
    "        if len(companies[company])>10:\n",
    "            example=companies[company]\n",
    "\n",
    "            example=example[['high','low','close']]\n",
    "            example=example[example['close'].notnull()]\n",
    "            example.drop('close',axis=1,inplace=True)\n",
    "            #massiv=[0]*len(example)\n",
    "            #for i in range(len(example)):\n",
    "                #vremya=str(example.iloc[i].date)+str(example.iloc[i].minute)\n",
    "                #massiv[i]=datetime.datetime.strptime(vremya,\"%Y%m%d%H:%M\")\n",
    "            #example.index=np.asarray(massiv)\n",
    "            #example.drop(['date','minute'], axis=1,inplace=True)\n",
    "            example.rename(columns={'high': 'High', 'low': 'Low'}, inplace=True)\n",
    "            example.index.name='Date'\n",
    "            example['company']=str(company)\n",
    "            traindata_standard[company]=example\n",
    "    return traindata_standard\n",
    "\n",
    "def get_traindata_standard_with_mart_2019(traindata_standard):\n",
    "    for company in traindata_standard.keys():\n",
    "        try:\n",
    "            df = pd.read_excel('C:/Users/user/Documents/Модуль биржа по фракталам/test_data_mart_2019/'+str(company)+'_'+'mart_2019.xlsx', index_col='Date')\n",
    "            traindata_standard[company]=df.append(traindata_standard[company])\n",
    "        except:\n",
    "            pass\n",
    "    return traindata_standard\n",
    "\n",
    "def traindata_standard_together(traindata_standard_previous, traindata_standard_current):\n",
    "    traindata_standard={}\n",
    "    for company in traindata_standard_previous.keys():\n",
    "        try:\n",
    "            df = traindata_standard_previous[company]\n",
    "            traindata_standard[company]=df.append(traindata_standard_current[company])\n",
    "        except:\n",
    "            pass\n",
    "    return traindata_standard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Общая работа с данными для получения ready_dataset_for_marking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ресэмплирование к периоду 1 час всех периодов (3, 7, 15 минут) - методом суммы по каждому периоду\n",
    "#оставляем только время от 09.00 до 16.00\n",
    "def get_resampled_dataset(unsampled_dataset):\n",
    "    resampled_dataset = unsampled_dataset.resample('H', label = 'right').sum()\n",
    "    return resampled_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#формирование датасета из цен фирм - для получения индекса рынка по часам\n",
    "def get_dataset_for_market_index(traindata_standard):\n",
    "    step = 0\n",
    "    companies = traindata_standard.keys()\n",
    "    DF={}\n",
    "    for company in companies:\n",
    "        df=traindata_standard[company].copy(deep=True)\n",
    "        df['price'] = (df['High'] + df['Low']) / 2\n",
    "        #df.drop(columns=['High', 'Low', 'company'], inplace=True)\n",
    "        DF[company] = df['price']\n",
    "    pddf=pd.DataFrame(DF)\n",
    "    df=pddf.resample('H', label = 'right').mean()\n",
    "\n",
    "    if step == 0:\n",
    "        indexes=pd.date_range(start=df.index[0], end=df.index[-1], freq='H')\n",
    "        dfs = pd.DataFrame(index=indexes)\n",
    "        dfs['day_number'] = dfs.index.date\n",
    "        dti=pd.date_range(start=df.index[0], end=df.index[-1], freq='B')\n",
    "        dfs_filtered=(dfs.loc[dfs['day_number'].isin(pd.DataFrame(index=dti).index.date)])\n",
    "        dfs_filtered_between_time=dfs_filtered.between_time(start_time='09:30', end_time='16:00')\n",
    "    df_filtered = (df.index.isin(dfs_filtered_between_time.index))\n",
    "    pddf=df[df_filtered]\n",
    "    \n",
    "    \n",
    "    step = step + 1    \n",
    "    \n",
    "\n",
    "    \n",
    "    #pddf=pddf.between_time(start_time='09:00', end_time='16:00')\n",
    "    #pddf=pddf.between_time(start_time='08:00', end_time='16:00')\n",
    "    dataset_for_market_index=pddf/pddf.shift(1)-1\n",
    "    dataset_for_market_index=(1+dataset_for_market_index).cumprod()\n",
    "    return dataset_for_market_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#получение столбца для добавления - индекс рынка по часам\n",
    "def get_market_index_by_hour(dataset_for_market_index):\n",
    "    return dataset_for_market_index.transpose().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_market_index_rolling(market_index_by_hour):\n",
    "    market_index_by_hour.dropna(inplace=True)\n",
    "    market_index_rolling = market_index_by_hour - market_index_by_hour.rolling(32).mean()\n",
    "    return market_index_rolling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_market_index_for_plotting(market_index_by_hour):\n",
    "    market_index_by_hour.dropna(inplace=True)\n",
    "    market_index_for_plotting = market_index_by_hour\n",
    "    return market_index_for_plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#получение датасета (с индексом рынка и только по бизнес-дням) для вычисления финального датасета\n",
    "def get_dataset_for_calculation(resampled_dataset, market_index_rolling):\n",
    "    resampled_dataset['market_index_rolling'] = market_index_rolling\n",
    "    mask = (resampled_dataset['market_index_rolling'].notnull())\n",
    "    dataset_for_calculation = resampled_dataset[mask]\n",
    "    return dataset_for_calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#получаем имена столбцов датасета\n",
    "def get_224__columnnames_for_dataset():\n",
    "    columns_mask = ['highes3','lowes3','highes7','lowes7','highes15','lowes15','market_index_rolling']\n",
    "    global_mask = []\n",
    "    for i in range(32):\n",
    "        mask = []\n",
    "        for j in columns_mask:\n",
    "            imya = str(i) + '_' + str(j)\n",
    "            mask.append(imya)\n",
    "        global_mask = global_mask + mask\n",
    "    return global_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#простираем вправо на 32 часа прежний датасет, с именами столбцов. датасет уже для маркировки\n",
    "def get_ready_dataset_for_marking(dataset_for_calculation):\n",
    "    calculated_dataset_for_marking = []\n",
    "    dataset_for_marking_indexes = []\n",
    "    for row in range(31, len(dataset_for_calculation)):\n",
    "        row_list=[]\n",
    "        for item in range(32):\n",
    "            row_list = row_list + list(dataset_for_calculation.iloc[row - item].values)\n",
    "        calculated_dataset_for_marking.append(row_list)\n",
    "        dataset_for_marking_indexes.append(dataset_for_calculation.index[row])\n",
    "    global_mask = get_224__columnnames_for_dataset()\n",
    "    ready_dataset_for_marking = pd.DataFrame(data=calculated_dataset_for_marking, index=dataset_for_marking_indexes, columns=global_mask)\n",
    "    return ready_dataset_for_marking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testdata\n",
      "traindata_standard_current\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['traindata_standard_01_03_2019__10_07_2019.pkl']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp500 = get_sp500(3)\n",
    "testdata = testdata_download(start_day=datetime.datetime(2019,7,3), #меняем даты здесь\n",
    "                             end_day=datetime.datetime(2019,7,10))\n",
    "print('testdata')\n",
    "traindata_standard_current = testdata_making_standard(testdata)\n",
    "print('traindata_standard_current')\n",
    "joblib.dump(traindata_standard_current, 'traindata_standard_03_07_2019__10_07_2019.pkl')#меняем даты здесь\n",
    "traindata_standard_previous=joblib.load('traindata_standard_01_03_2019__02_07_2019.pkl')\n",
    "                                            #меняем даты здесь\n",
    "traindata_standard = traindata_standard_together(traindata_standard_previous,\n",
    "                                                 traindata_standard_current)\n",
    "joblib.dump(traindata_standard, 'traindata_standard_01_03_2019__10_07_2019.pkl')\n",
    "                                            #меняем даты здесь"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "unsampled_dataset = get_unsampled_dataset(traindata_standard, times = [3,7,15])\n",
    "resampled_dataset = get_resampled_dataset(unsampled_dataset)\n",
    "dataset_for_market_index = get_dataset_for_market_index(traindata_standard)\n",
    "market_index_by_hour=get_market_index_by_hour(dataset_for_market_index)\n",
    "market_index_rolling = get_market_index_rolling(market_index_by_hour)\n",
    "dataset_for_calculation = get_dataset_for_calculation(resampled_dataset, market_index_rolling)\n",
    "ready_dataset_for_marking = get_ready_dataset_for_marking(dataset_for_calculation)\n",
    "ready_dataset_for_marking.to_excel('ready_dataset_for_marking_last_10_07_2019.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Подумать над решением вопроса про 163 компании. Надо чтобы до 18 июня включительно было 164 компании, как прежде"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindata_standard=joblib.load('traindata_standard_19_06_2019__02_07_2019.pkl')\n",
    "traindata_standard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(traindata_standard['AOS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
